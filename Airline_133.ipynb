{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlySerry0/CSEN903-Airline-Team-133/blob/main/Airline_133.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AlySerry0/CSEN903-Airline-RawData.git\n",
        "\n",
        "raw_data_dir = '/content/CSEN903-Airline-RawData'"
      ],
      "metadata": {
        "id": "ZoEe1bkbdk3f",
        "outputId": "baa48b37-c6e5-4684-c46e-f05ae181d0e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Cloning into 'CSEN903-Airline-RawData'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "rVkICqqnZ6iw",
        "outputId": "c7e83427-1a80-459f-e290-316307e525bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: requests in c:\\python313\\lib\\site-packages (from vaderSentiment) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python313\\lib\\site-packages (from requests->vaderSentiment) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python313\\lib\\site-packages (from requests->vaderSentiment) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python313\\lib\\site-packages (from requests->vaderSentiment) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python313\\lib\\site-packages (from requests->vaderSentiment) (2025.10.5)\n",
            "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m get_ipython().system(\u001b[33m'\u001b[39m\u001b[33mpip install vaderSentiment\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvaderSentiment\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvaderSentiment\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentimentIntensityAnalyzer\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "!pip install vaderSentiment\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AirlineScrappedReview = pd.read_csv(f'{raw_data_dir}/AirlineScrappedReview_Cleaned.csv')\n",
        "AirlineScrappedReview.info()"
      ],
      "metadata": {
        "id": "_jFcYcJLbuit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AirlineScrappedReview.head()"
      ],
      "metadata": {
        "id": "1QJoiJmZppEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AirlineScrappedReview.isnull().sum()"
      ],
      "metadata": {
        "id": "TAsgHFZTpqr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AirlineScrappedReview.describe(include='all')"
      ],
      "metadata": {
        "id": "ReTbwc-PpuJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = [\n",
        "    'Flying_Date', 'Layover_Route',        # Too many missing values\n",
        "    'Passanger_Name', 'Review_title',       # Unneeded identifiers\n",
        "    'Start_Latitude', 'Start_Longitude',    # Redundant location data\n",
        "    'Start_Address', 'End_Latitude',\n",
        "    'End_Longitude', 'End_Address',\n",
        "    'Start_Location', 'End_Location'      # Redundant to 'Route'\n",
        "]\n",
        "AirlineScrappedReview = AirlineScrappedReview.drop(columns=columns_to_drop)\n",
        "# AirlineScrappedReview = AirlineScrappedReview.dropna()"
      ],
      "metadata": {
        "id": "rlYX0ThLq_QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AirlineScrappedReview['Satisfaction'] = (AirlineScrappedReview['Rating'] >= 5).astype(int)\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "AirlineScrappedReview['Sentiment_Score'] = AirlineScrappedReview['Review_content'].apply(\n",
        "    lambda review: sia.polarity_scores(review)['compound']\n",
        ")"
      ],
      "metadata": {
        "id": "I7MoXc2Jrgy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Encode Binary 'Verified' Column ---\n",
        "# Map 'Trip Verified' to 1 and 'Not Verified' to 0\n",
        "AirlineScrappedReview['Verified'] = AirlineScrappedReview['Verified'].map({\n",
        "    'Trip Verified': 1,\n",
        "    'Not Verified': 0\n",
        "})\n",
        "\n",
        "# --- 6. One-Hot Encode 'Traveller_Type' and 'Class' ---\n",
        "AirlineScrappedReview = pd.get_dummies(AirlineScrappedReview,\n",
        "                            columns=['Traveller_Type', 'Class'],\n",
        "                            drop_first=True)\n",
        "\n",
        "AirlineScrappedReview = AirlineScrappedReview.drop_duplicates()\n",
        "\n",
        "# Display the final prepped DataFrame\n",
        "print(\"\\n--- Final Prepped DataFrame ---\")\n",
        "AirlineScrappedReview.info()"
      ],
      "metadata": {
        "id": "fcODX-h0rqRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Customer_comment = pd.read_csv(f'{raw_data_dir}/Customer_comment.csv')"
      ],
      "metadata": {
        "id": "Sd06p1lNcBTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Customer_comment.info()"
      ],
      "metadata": {
        "id": "uxPzbuYxr_28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Customer_comment.head()"
      ],
      "metadata": {
        "id": "UrWM_BM7r_28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Customer_comment.isnull().sum()"
      ],
      "metadata": {
        "id": "ITUvOzFzr_28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Customer_comment.describe(include='all')"
      ],
      "metadata": {
        "id": "y25bo8ljr_28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Unique Values in Key Columns ---\")\n",
        "cols_to_check = ['arrival_delay_group', 'departure_delay_group', 'entity',\n",
        "                 'seat_factor_band', 'loyalty_program_level', 'fleet_usage', 'response_group', 'sentiments']\n",
        "\n",
        "for col in cols_to_check:\n",
        "    print(f\"Column '{col}': {Customer_comment[col].unique()}\")"
      ],
      "metadata": {
        "id": "wYcWB09enciz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6660b7b"
      },
      "source": [
        "# --- 1. Drop Unnecessary/Redundant Columns ---\n",
        "columns_to_drop = [\n",
        "    'Unnamed: 0',         # Duplicate index\n",
        "    'ques_verbatim_text', # Only has one unique value, no info\n",
        "    'transformed_text'    # Incomplete, and we have the raw 'verbatim_text'\n",
        "]\n",
        "Customer_comment = Customer_comment.drop(columns=columns_to_drop)\n",
        "\n",
        "# --- 2. Handle Missing Data ---\n",
        "# Fill missing loyalty levels with 'None'\n",
        "Customer_comment['loyalty_program_level'] = Customer_comment['loyalty_program_level'].fillna('None')\n",
        "\n",
        "# --- 3. Convert Data Types ---\n",
        "# Convert date column to datetime objects\n",
        "Customer_comment['scheduled_departure_date'] = pd.to_datetime(Customer_comment['scheduled_departure_date'])\n",
        "\n",
        "# --- 4. Encode Binary Categorical Columns ---\n",
        "# We'll map the \"negative\" or \"delayed\" state to 1 and the \"positive\" state to 0\n",
        "\n",
        "Customer_comment['arrival_delay_group'] = Customer_comment['arrival_delay_group'].map({\n",
        "    'Delayed': 1,\n",
        "    'Early & Ontime': 0\n",
        "})\n",
        "\n",
        "Customer_comment['departure_delay_group'] = Customer_comment['departure_delay_group'].map({\n",
        "    'Delayed': 1,\n",
        "    'Early & Ontime': 0\n",
        "})\n",
        "\n",
        "Customer_comment['sentiments'] = Customer_comment['sentiments'].map({\n",
        "    'Negative': 1,\n",
        "    'Neutral': 0\n",
        "})\n",
        "\n",
        "# --- 5. Encode Ordinal 'seat_factor_band' Column ---\n",
        "band_mapping = {\n",
        "    '0 to 70': 0,\n",
        "    '70+': 1,\n",
        "    '80+': 2,\n",
        "    '90+': 3\n",
        "}\n",
        "\n",
        "Customer_comment['seat_factor_band'] = Customer_comment['seat_factor_band'].map(band_mapping)\n",
        "\n",
        "Customer_comment = Customer_comment.drop_duplicates()\n",
        "\n",
        "\n",
        "Customer_comment.info()\n",
        "Customer_comment.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}